{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Common Errors from Names Using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.max_row\",None)\n",
    "import nltk\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-8b8d5ed3cfb4>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.Text = df.Text.str.replace(r\"MICROFILM|MICROFILM MANUSCRIPTS|Treasure room|MANUSCRIPTS Restricted|MANUSCRIPTS|^Chapel|MSS|NUCMC|^FILM|^RESTRICTED\",\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"catalog\\main_file_all_text.csv\")\n",
    "df.drop(columns='Unnamed: 0',inplace=True)\n",
    "df.rename(columns={\"0\":\"Text\"},inplace=True)\n",
    "# Replace the common unwanted words appearing in the beginning of rows\n",
    "df.Text = df.Text.str.replace(r\"MICROFILM|MICROFILM MANUSCRIPTS|Treasure room|MANUSCRIPTS Restricted|MANUSCRIPTS|^Chapel|MSS|NUCMC|^FILM|^RESTRICTED\",\n",
    "\"\",case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNKING WITH NO START LETTER PARAMETER\n",
    "def chunk(df):\n",
    "    word_tok = nltk.word_tokenize(df[:50])\n",
    "    taged_sent= nltk.pos_tag(word_tok)\n",
    "    # Checks for Proper Noun,  coordinating conjunction(and,&), Proper Nouns\n",
    "    #TODO Improve this pattern to better extract names\n",
    "    grammar = \"Name: {((<NNP><,>)?<NNP><.>?<CC>?<NNP>?<CC>?<NNP>*)}\"\n",
    "    cp = nltk.RegexpParser(grammar,loop=1)\n",
    "    chunked = cp.parse(taged_sent)\n",
    "    for subtree in chunked.subtrees(filter =  lambda x : x.label()==\"Name\"):\n",
    "         # Generate all subtrees\n",
    "        return \" \".join([i[0] for i in subtree.leaves()])\n",
    "\n",
    "\n",
    "df[\"Name\"] = df.Text.apply(chunk)\n",
    "# Modify comma and space, replace common unwanted word endings/titles\n",
    "\n",
    "endings = [\"Papers\", \"Letters\", \"Diary\", \"Notebook\", \"Book\", \"Scrapbook\", \"Screenplay\", \"Memoir\", \"Card\", \"Daybook\", \"Day\", \n",
    "           \"Account\", \"Sketch\", \"Journal\", \"Letter\", \"Record\", \"Notes\", \"Ledger\", \"Rent\", \"Letterpress\", \"Address\",\"War\"]\n",
    "for i in endings:\n",
    "    df.Name = df.Name.str.replace(i,\"\",case=False)\n",
    "df.Name = df.Name.str.replace(\" , \",\", \")\n",
    "df.Name = df.Name.str.replace(\"For Information.*\",\"\")\n",
    "df.Name = df.Name.str.strip()\n",
    "df.Name = df.Name.str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNKING WITH START LETTER PARAMETER\n",
    "def chunk(df,start_letter):\n",
    "    start_letter = start_letter.upper()\n",
    "    df =  re.sub(r'[0-9]+', '', df)\n",
    "    first_ind = df.find(start_letter)\n",
    "    # If word starting with start letter does not exist, return None\n",
    "    if(first_ind ==-1):\n",
    "        return None\n",
    "    word_tok = nltk.word_tokenize(df[first_ind:50+first_ind])\n",
    "    taged_sent= nltk.pos_tag(word_tok)\n",
    "    # Checks for Proper Noun,  coordinating conjunction(and,&), Proper Nouns\n",
    "    grammar = \"Name: {((<NN.><,>)?<NNP><.>?<CC>?<NNP>?<CC>?<NNP>*)}\"\n",
    "    cp = nltk.RegexpParser(grammar,loop=1)\n",
    "    chunked = cp.parse(taged_sent)\n",
    "    for subtree in chunked.subtrees(filter =  lambda x : x.label()==\"Name\"):\n",
    "         # Generate all subtrees\n",
    "        li = [i[0] for i in subtree.leaves()]\n",
    "#         print(li)\n",
    "        \n",
    "        if li[0].startswith(start_letter):\n",
    "            return \" \".join([i[0] for i in subtree.leaves()])\n",
    "        # if no chunk start with the letter\n",
    "        # Get the first word starting with the letter\n",
    "        for i in chunked.leaves():\n",
    "            if i[0].startswith(start_letter):\n",
    "                first = i[0]\n",
    "        return first + \", \"+ \" \".join(li)\n",
    "\n",
    "\n",
    "# Apply chunking / put in start_letter \n",
    "df[\"Name\"] = df.Text.apply(chunk, start_letter)\n",
    "# Modify comma and space, replace common unwanted word endings/titles\n",
    "\n",
    "endings = [\"Papers\", \"Letters\", \"Diary\", \"Notebook\", \"Book\", \"Scrapbook\", \"Screenplay\", \"Memoir\", \"Card\", \"Daybook\", \"Day\", \n",
    "           \"Account\", \"Sketch\", \"Journal\", \"Letter\", \"Record\", \"Notes\", \"Ledger\", \"Rent\", \"Letterpress\", \"Address\",\"War\"]\n",
    "for i in endings:\n",
    "    df.Name = df.Name.str.replace(i,\"\",case=False)\n",
    "df.Name = df.Name.str.replace(\" , \",\", \")\n",
    "df.Name = df.Name.str.replace(\"For Information.*\",\"\")\n",
    "df.Name = df.Name.str.strip()\n",
    "df.Name = df.Name.str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"all_text_chunked_name.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
